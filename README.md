# ai_pd.io
Правовое регулирование искусственного интеллекта в контексте защиты персональных данных
https://elib.bsu.by/bitstream/123456789/297975/1/31-39.pdf Липская С.А., Правовое регулирование искусственного интеллекта / С.А. Липская // Право интеллектуальной собственности Республики Беларусь: история становления и перспективы : сборник статей международного научно-практического круглого стола, Минск, 19 апреля 2022 г. / БГУ, Юридический факультет ; [редкол.: Д. В. Иванова (отв. ред.), Д. Д. Ландо, О. О. Ядревский]. – Минск : БГУ, 2023. – С. 31-39.
Вопрос необходимости правового регулирования ИИ среди правоведов активизировался в 1970-х гг. западными юристами. На постсоветском пространстве потребность регулирования вопросов ИИ стала очевидной только последнее десятилетие. В настоящее время правовое регулирование ИИ является одним из первоочередных для большинства стран, так как позволяет заявить о лидерских позициях на международной арене. Большинство правоведов в исследованиях и выносимых выводах не ставят разделение между ИИ и роботами, так как подход в регулировании идентичен. Именно ученые и их научные исследования часто становятся идейными вдохновителями правового регулирования конкретных вопросов, а также систематизации законодательной базы большинства государств. Бесспорными мировыми лидерами в ИИ, разработке, внедрении и правовом регулировании, являются Соединенные Штаты Америки и Китайская Народная Республика. Автор рассматривает современное положение правового регулирования искусственного интеллекта в названных странах. Автор отмечает, что что при стремлении быть лидерами в вопросах применения ИИ, принятии значительного количества законов, иных актов, акцентировании внимания на необходимости стандартизации ИИ, политике защиты и конфиденциальности данных, применения ИИ в охране правопорядка, можно выделить основные отличия данных подходов. В Республике Беларусь отсутствует закрепление термина «искусственный интеллект».  В Республике Беларусь правовое регулирование ИИ, а именно, объектов, которые разрабатываются, создаются с применением ИИ является открытым и нерешенным вопросом. Целесообразным является принятие мер по правовому регулированию ИИ в Республики Беларусь путем введения норм по стандартизации ИИ, принятию этических правил (норм), стратегии развития ИИ в национальных интересах, что обеспечит привлекательность государства в целом на международной арене.

https://cyberleninka.ru/article/n/osobennosti-sbora-obrabotki-i-zaschity-personalnyh-dannyh-iskusstvennym-intellektom/pdf Литвин И.И., Особенности сбора, обработки и защиты персональных данных искусственным интеллектом / И.И. Литвин // Вестник Уральского юридического института МВД России – 2021. - №4 – С. 112-118.
В статье рассматривается влияние технологий искусственного интеллекта на правовое регулирование оборота персональных данных и некоторые особенности сбора, обработки и защиты персональных данных с помощью искусственного интеллекта. Автор анализирует законодательство о персональных данных, рассматривает существующие технологии искусственного интеллекта, применяемые для обработки персональных данных, исследует взаимосвязь «больших данных» с возможностью их обработки искусственным интеллектом. В завершение рассматривается вопрос ответственности искусственного интеллекта за причинение вреда при нарушении конфиденциальности персональных данных. Вопрос ответственности искусственного интеллекта не ограничивается лишь областью правового регулирования персональных данных, а и в уголовном, административном, трудовом, и гражданском праве. В законодательстве о персональных данных правовой статус искусственного интеллекта не определен, однако существует разделение между обработкой данных с использованием средств автоматизации и без использования таковых. Использование искусственного интеллекта в целях сбора, обработки и защиты персональных данных соответствующего правового регулирования и при этом обуславливается специфическими возможностями искусственного интеллекта: способность собирать данные через взаимодействие с метаданными сайта (файлы-cookie); способность обрабатывать большие объемы данных и делать на их основе прогнозы с определенной точностью; способность непрерывно участвовать в анализе конфиденциальности и параметров защиты; способность обучаться поиску уязвимостей и передавать опыт другим системам искусственного интеллекта; способность обрабатывать данные без участия оператора данных, а следовательно, без фактического распространения сведений о личной жизни субъекта персональных данных. 

https://journals.vsu.ru/law/article/download/3722/9036/ Тлембаева Ж.У., О некоторых вопросах правового регулирования использования технологии искусственного интеллекта в условиях цифровой трансформации / Ж.У. Тлембаева // Вестник Воронежского государственного университета. Серия: Право. – 2021. - №4. – С. 331-348. 
Статья посвящена исследованию вопросов правового регулирования разработки и использования искусственного интеллекта на международном и национальном уровнях. Проведен анализ международных актов, изучена деятельность международных организаций по формированию международно-правовой основы по вопросам, связанным с регулированием искусственного интеллекта. Сравнительному исследованию подвергнуты национальные стратегии, законодательство в сфере искусственного интеллекта таких стран, как Корея, США, Япония, Китай, Россия, Казахстан, а также стран - участниц Европейского союза. Выявлены особенности законодательного обеспечения данной сферы в Республике Казахстан. Проанализированы: Государственная программа «Цифровой Казахстан», Стратегический план развития Республики Казахстан до 2025 г., положения ежегодных посланий Президента Республики Казахстан народу Казахстана относительно вопросов создания и использования искусственного интеллекта. Сформулирован вывод, что в современных условиях возникает настоятельная потребность в установлении глобальных стандартов регулирования искусственного интеллекта и использования его положений в качестве модели для формирования внутреннего законодательства государств. Автор утверждает, что развитие глобализации и появление новых вызовов и угроз, связанных с применением новых технологий, несомненно, влечет трансформацию системы международного права и требует обсуждения вопросов правового обеспечения создания и применения технологий искусственного интеллекта. Анализ мировой практики регулирования искусственного интеллекта в условиях глобализации свидетельствует о трансформации системы международного права. В условиях, когда развитие технологий искусственного интеллекта порождает вызовы и создает много рисков и неопределенностей, возникает настоятельная потребность в установлении глобальных стандартов регулирования искусственного интеллекта и использования его положений в качестве модели для формирования внутреннего законодательства государств.

https://libeldoc.bsuir.by/bitstream/123456789/52770/1/Krachkovskii_Obzor.pdf Крачковский, А. В. Обзор международного опыта правового регулирования искусственного интеллекта / А. В. Крачковский, М. В. Гриненко // Актуальные вопросы экономики и информационных технологий : сборник тезисов и статей докладов 59-ой научной конференции аспирантов, магистрантов и студентов БГУИР, Минск, 17–21 апреля 2023 г. / Белорусский государственный университет информатики и радиоэлектроники. – Минск, 2023. – С. 274-276.
Искусственный интеллект, включающий в себя такие технологии, как машинное обучение, обработку естественного языка, машинное рассуждение и многое другое, стремительно внедряются в нашу повседневную жизнь. Важной проблемой эффективного правового регулирования внедрения и использования искусственного интеллекта является то, что искусственный интеллект – сложное и комплексное понятие. В исследовании отмечается необходимость учета зарубежного опыта при определении собственных концептуальных подходов по регулированию общественных отношений в сфере искусственного интеллекта, а также гармонизации подходов к правовому регулированию рассматриваемых технологий в рамках Евразийского экономического союза, учет общемировых тенденций. На сегодняшний день государственные стратегии по применению искусственного интеллекта разработаны во многих государствах мира, таких как США, Канада, государства Европейского Союза, Китай и многие другие. Рассматривается правовое регулирование искусственного интеллекта в таких странах, как США, Канада, Южная Корея, Российская Федерация. Анализируется подход к правовому регулированию в Республике Беларусь. Обзор отечественного и зарубежного законодательства, регулирующего вопросы искусственного интеллекта, находится в процессе своего становления и осуществляется, как правило, на уровне стратегий, планов как основополагающих и направляющих дальнейшее правовое развитие документов. Государства в рамках правового регулирования внедрения искусственного интеллекта уделяют существенное внимание таким вопросам, как: сохранение баланса между необходимостью включить искусственный интеллект в существующее правовое поле и важностью сохранения естественного хода технического прогресса; кадровое обеспечение сферы искусственного интеллекта; определение норм этики, регулирующих функционирование и применение искусственного интеллекта, в том числе предотвращение выхода данных технологий из-под контроля государства.

https://lawjournal.spbu.ru/article/download/9346/7929/ Егорова М.А., Минбалеев А.В. , Кожевина О.В., Дюфло А. Основные направления правового регулирования использования искусственного интеллекта в  условиях пандемии / М.А. Егорова, А.В. Минбалеев, О.В. Кожевина, А. Дюфло // Вестник Санкт-Петербургского университета. Право. – 2021. – Т. 12 Вып. 2. – С. 250–262. 
Технологии искусственного интеллекта сегодня рассматриваются как неотъемлемая часть жизни нашего общества. Исследование вопросов использования искусственного интеллекта осуществляется на стыке многих областей наук, не стала исключением и юриспруденция. В последние годы наметилась тенденция гармонизации права в соответствии с новыми вызовами и  глобальными трендами развития информационного общества, внедрения информационно-коммуникационных технологий в  общественные процессы. Это обусловливает изменение системы общественных отношений и формирование специфических отраслей и подотраслей права, в частности информационного (цифрового) права. Российская Федерация, как и большинство современных государств, ставит серьезные задачи по созданию системы правового регулирования искусственного интеллекта. Данная задача особенно актуализировалась в условиях распространения пандемии коронавирусной инфекции COVID-19, ставшей фактором, повлиявшим на активизацию процессов внедрения технологий искусственного интеллекта. Авторы статьи поднимают вопрос о наиболее важных направлениях регулирования использования искусственного интеллекта, в первую очередь для устойчивого развития экономики в условиях пандемии, а также для активизации инновационного технологического предпринимательства. Проанализированы стратегические документы и правовая основа регулирования искусственного интеллекта, науки и технологий цифровой экономики в России. На основе изучения зарубежной практики нормативного правового регулирования цифровой экономики и искусственного интеллекта выявлены особенности подходов в Европе и Восточной Азии. Обозначена проблема цифровой этики и этики искусственного интеллекта в условиях пандемии COVID-19, определены перспективы развития российского законодательства в области искусственного интеллекта. Авторами отмечается, что Наибольшую опасность представляет использование информации различными роботами, специализированными системами сбора и обработки персональных данных, а также их обработка с использованием технологии больших данных. Персональные данные уже используются огромным количеством устройств по всему мире, и их число экспоненциально растет с распространением интернета вещей и промышленного. Увеличение объемов обрабатываемой информации в условиях пандемии не позволяет справиться с ней при помощи только автоматизированных систем обработки информации, операторы вынуждены прибегать к более современным системам ИИ.

https://vestnik.susu.ru/law/article/download/10211/8039 Минбалеев, А. В. Проблемы защиты персональных данных и цифрового профиля человека в сети интернет в условиях пандемии / А. В. Минбалеев, В. А. Филоненкова // Вестник ЮУрГУ. Серия «Право». – 2020. – Т. 20, № 3. – С. 89–94. 
Статья посвящена исследованию проблем защиты персональных данных и цифрового профиля человека в условиях пандемии. В условиях развития в России и во всем мире пандемии коронавируса COVID-19 очень серьезной проблемой является необходимость обеспечения и защиты персональных данных, в первую очередь о состоянии здоровья граждан, а также данных, которые государства получают в результате контроля за гражданами и соблюдением ими режима самоизоляции, социального дистанцирования и иных противоэпидемиологических мер, которые вводит государство в борьбе с пандемией. Особая опасность связана с тем, что большая часть таких данных размещается в сети Интернет, в связи с чем возникают значительные риски того, что эта информация может быть незаконно получена с помощью хакерских атак и незаконно распространена. Социальный скоринг часто основывается на использовании технологий big data и искусственного интеллекта. В этом случае искусственный интеллект обрабатывает огромное количество данных клиентов, анализирует их социальные характеристики и на основе этих больших данных ранжирует пользователей. Делается вывод о том, что компании, планирующие такое использование персональных данных, должны в качестве специальной цели обработки уведомлять Роскомнадзор, выделять данную цель в процессе обработки персональных данных и получать специальное согласие субъектов персональных данных на такое согласие. Наряду с необходимостью обеспечения защиты прав на персональные данные в условиях пандемии допускаются определенные ограничения, обусловленные необходимостью защиты прав и законных интересов граждан на здоровье, а также защиты общества от угрозы пандемии. В этой связи вполне оправдано на период пандемии расширить возможности обработки персональных данных, в том числе в информационно-телекоммуникационных сетях и сети Интернет, без согласия субъекта персональных данных. Однако данные меры должны быть привязаны к официальному состоянию режима повышенной готовности или чрезвычайному режиму, носить временный характер и после окончания отменены.

https://www.periodica.org/index.php/journal/article/download/791/667/751 Набижонов А.А. угли, Правовое регулирование искусственного интеллекта: теория и практика / А.А. угли Набижонов // Periodica Journal of Modern Philosophy, Social Sciences and Humanities. – Vol. 30. – May 2024. – С. 78-80. 
Статья "Правовое регулирование искусственного интеллекта: вызовы и перспективы" исследует актуальную проблематику правового регулирования применения искусственного интеллекта в современном обществе. Автор анализирует основные аспекты, включая определение прав и обязанностей владельцев и разработчиков ИИ, вопросы ответственности за действия автономных систем, защиту данных и конфиденциальности, а также этические дилеммы. Статья также рассматривает международные аспекты и сотрудничество в области регулирования ИИ, а также важность обучения и осведомленности общества о правовых аспектах использования искусственного интеллекта. Автор утверждает, что правовое регулирование искусственного интеллекта является сложным и многогранным процессом, который требует сбалансированного подхода, учитывающего технические, этические и социальные аспекты его применения. Развитие соответствующей теории и практики важно для обеспечения безопасного и ответственного использования ИИ в современном мире. В заключение, автор подчеркивает необходимость гибкости и постоянного обновления законодательства для эффективного урегулирования изменяющейся технологической среды. Делается вывод о том, что правовое регулирование искусственного интеллекта охватывает широкий спектр вопросов, включая законы, этические принципы, ответственность, защиту данных и обеспечение общественного доверия. Новейшие тенденции в этой области связаны с разработкой законодательства, стандартов и механизмов контроля, а также с обсуждением вопросов ответственности, обучения ИИ и защиты интеллектуальной собственности. Эти меры направлены на обеспечение безопасного и этичного развития и использования искусственного интеллекта.

https://cyberleninka.ru/article/n/pravovye-sredstva-obespecheniya-printsipa-prozrachnosti-iskusstvennogo-intellekta/pdf Харитонова Ю.С., Правовые средства обеспечения принципа прозрачности искусственного интеллекта / Ю.С. Харитонова // Journal of Digital Technologies and Law. – 2023. – №1(2). – С. 337-358.
Подвергнуты критическому анализу нормы и предложения для нормативного оформления принципа прозрачности искусственного интеллекта с точки зрения невозможности получения полной технологической прозрачности искусственного интеллекта. Выдвинуто предложение обсудить варианты политики управления алгоритмической прозрачностью и подотчетностью на основе анализа социальных, технических и регулятивных проблем, создаваемых алгоритмическими системами искусственного интеллекта. Обосновано, что прозрачность является необходимым условием для признания искусственного интеллекта заслуживающим доверия. Обосновано, что прозрачность и объяснимость технологии искусственного интеллекта важна не только для защиты персональных данных, но и в иных ситуациях автоматизированной обработки данных, когда для принятия решений недостающие из входящей информации технологические данные восполняются из открытых источников, в том числе не имеющих значения хранилищ персональных данных. Предложено законодательно закрепить обязательный аудит и ввести стандарт, закрепляющий компромисс между возможностями и преимуществами технологии, точностью и объяснимостью результата ее работы и правами участников общественных отношений. Введение сертификации моделей искусственного интеллекта, обязательных к применению, позволит решить вопросы ответственности обязанных применять такие системы субъектов. В контексте вопроса о профессиональной ответственности профессиональных субъектов, таких как врачи, военные, органы корпоративного управления юридического лица, требуется ограничить обязательное применение искусственного интеллекта в случаях, если не обеспечена его достаточная прозрачность. Делается вывод о том, что развитие правовой дискуссии должно двигаться по выработке предложений о содержании права на отказ от применения автоматизированной обработки данных для принятия решений и права на возражения против принятых таким способом решений.

https://cyberleninka.ru/article/n/grazhdansko-pravovoe-regulirovanie-iskusstvennogo-intellekta-v-rossiyskoy-federatsii/pdf Трохов М.С., Колоскова О.А., Глазов И.Д. — Гражданско-правовое регулирование искусственного интеллекта в Российской Федерации // Юридические исследования. – 2023. – № 3.
Целью данной статьи является выявление нормотворческих пробелов нормативно-правого регулирования применения технологии искусственного интеллекта и связанных с ней системами, а также выявление степени необходимости более ёмкого правового регулирования. Предметом представленной работы являются проблемы детерминации технологии искусственного интеллекта через призму правовой системы, а именно: выявление проблем, связанных определением понятия технологии искусственного интеллекта с опорой на нормативные источники и юридическую доктрину, выявлением границ существующего нормативно-правового регулирования и правоприменения технологии искусственного интеллекта, а также определения правого статуса представленной технологии, определение данной технологии в системе гражданско-правовых отношений путем сравнительного анализа свойств технологии искусственного интеллекта со свойствами каждого из элементов правоотношений. В ходе написания работы была применена методология, основанная на сборе данных о законодательных актах и правовом регулировании, а также аналитики и сравнения в области применения технологий искусственного интеллекта. Новизна данной статьи заключается в том, что она обсуждает актуальную тему правового регулирования и нормативного контроля за развитием и использованием искусственного интеллекта. Авторы исследуют этические аспекты использования ИИ и сравнивают различные определения ИИ, включая те, которые приняты Организацией Объединенных Наций, Европейским союзом и Российской Федерацией. Авторы приходят к выводу, что регулирование использования ИИ в правовом контексте является актуальной и важной проблемой, которую нужно решить для защиты прав и свобод граждан и обеспечения безопасности и ответственности при использовании технологий искусственного интеллекта. 

https://cyberleninka.ru/article/n/pravovoe-regulirovanie-i-oblast-primeneniya-iskusstvennogo-intellekta/pdf  Поздеева В.С., Правовое регулирование и область применения искусственного интеллекта / В.С. Поздеева // Вопросы российской юстиции – 2022. - №22. – С. 249-260. 
В современном цифровом пространстве вопросы применения искусственного интеллекта и сфера разработки интеллектуальных технологий являются крайне важными и актуальными. В статье рассматривается правовое регулирование и область применения искусственного интеллекта, как в повседневном, так и в юридическом направлениях. Ключевыми нормативными правовыми актами, регулирующими названный вопрос в Российской Федерации, являются Программа «Цифровая экономика Российской Федерации», утвержденной Постановлением Правительства Российской Федерации от 28 июля 2017 года №1632-р, Указ Президента Российской Федерации от 10 октября 2019 года №490 «О развитии искусственного интеллекта в Российской Федерации». Рассматриваются различные отрасли, в которых применяется технология искусственного интеллекта. В заключении автор утверждает, что проблема обеспечения безопасности конфиденциальной информации, в том числе проблема обеспечении кибербезопасности и использованием искусственного интеллекта, является одной из ключевых для всех субъектов цифровой экономики. Стоит считать проблемой самостоятельное развитие искусственного интеллекта, которое может привести к не очень утешительным последствиям. Но помимо этого в настоящее время использование искусственного интеллекта позволило добиться огромного количества положительного результата, благодаря которому была облегчена жизнедеятельность людей. Онлайн-правосудие упрощает взаимодействие граждан с судебными органами, например, предусматривает процедуру подачи искового заявления, других процессуальных документов в электронном виде. Также в законопроектной деятельности искусственный интеллект можно использовать, в двух направлениях: 1) как инструмент, обслуживающий потребности законопроектной деятельности, в том числе юридической техники; 2) в перспективе как робота-законодателя, который участвует в процессе разработки проекта правового решения.

https://cyberleninka.ru/article/n/personalnye-dannye-v-sistemah-iskusstvennogo-intellekta-tehnologiya-obrabotki-estestvennogo-yazyka/pdf Ильин И.Г. Персональные данные в системах искусственного интеллекта: технология обработки естественного языка / И.Г. Ильин // Journal of Digital Technologies and Law. – 2024. – №2(1). – С. 123-140. 
В ходе исследования установлено, что соблюдение режима персональных данных в процессе разработки технологии обработки естественного язык приводит к возникновению конфликта между частными и публично-правовыми интересами, что, в свою очередь, создает препятствия для дальнейшего развития обозначенной технологии. Показаны недостатки существующего правопорядка, который не в полной мере отвечает техническим особенностям развития технологии, что может привести к рискам излишнего регулирования, или же, напротив, к рискам оставления без внимания критических областей, требующих защиты. Обозначены проблемы при квалификации данных, задействованных в развитии рассматриваемой технологии. Предпринята попытка определить пределы обеспечения законности обработки персональных данных в составе технологии обработки естественного языка. Выделено в качестве пределов обеспечения законности материальное, временное и территориальное действие правового регулирования в данной области. Затрагивается проблема возможности использования персональных данных в качестве встречного представления, что является важным для развития технологии обработки естественного языка и для совершенствования отрасли информационно-коммуникационных технологий. Попытка определить пределы обеспечения законности обработки данных также вызывает трудности и требует дальнейшего уточнения как в части материального, так и временного и территориального действия правового регулирования в данной области. Еще одним вопросом, нуждающимся в дальнейшем исследовании, является возможность использования персональных данных в качестве встречного представления. Данная проблема представляется актуальной не только для развития технологии обработки естественного языка, но и в целом для развития отрасли информационно-коммуникационных технологий. 

https://cyberleninka.ru/article/n/regulirovanie-i-zaschita-personalnyh-meditsinskih-dannyh-v-epohu-ii-mezhdunarodnyy-opyt/pdf Галкина Н. М., Кузнецова Д. В. Регулирование и защита персональных медицинских данных в эпоху ИИ: международный опыт / Н.М. Галкина, Д.В. Кузнецова // Теоретическая и прикладная юриспруденция. – 2024. – № 3 (21) – С. 96-106. 
Искусственный интеллект активно захватывает сферу за сферой, в том числе особые успехи и достижения можно видеть в сфере медицины и медицинских технологий. Однако внедрение искусственного интеллекта ставит целый ряд вопросов как практического, так и этического характера. Управление персональными данными становится ключевым вопросом при разработке искусственного интеллекта в медицине, поскольку эффективность таких систем напрямую зависит от доступа к обширным медицинским данным пациентов. Самым удобным решением для их использования является предварительная анонимизация. Однако при анонимизации существует риск повторной идентификации, а также возможна утрата потенциала информативности данных. В рамках настоящей статьи на примере США, ЕС и Сингапура рассматривается опыт в сфере правового регулирования обращения с медицинскими персональными данными при использовании систем искусственного интеллекта в медицине. Каждая из стран пытается найти баланс между защитой конфиденциальности персональных данных и развитием инноваций. На основе проведенного анализа можно сделать вывод, что фокус на развитие искусственного интеллекта требует определенных допущений в области защиты персональных данных, в то время как высокий жесткий стандарт защиты персональных данных может оказывать сдерживающее действие. В рамках сравнительно-правового анализа законодательств о защите данных в Европейском союзе, США и Сингапуре особенное внимание следует уделить различиям в подходах к анонимизации данных. Эти различия отражают как общие цели законодательства, так и специфические правовые и культурные контексты каждой юрисдикции.

https://cyberleninka.ru/article/n/sistema-raspoznavaniya-lits-v-kontekste-prav-cheloveka-na-zaschitu-personalnyh-dannyh/pdf  Семелькина П.Д., Система распознавания лиц в контексте прав человека на защиту персональных данных / П.Д. Семелькина // Теория и практика современной науки – 2022. – №10(88). – С. 125-129.
В XXI веке стремительно происходит развитие информационных технологий, а также и внедрение разного рода “умных” машин, роботов. Искусственный интеллект стоит на пути вытеснения людей с рабочих мест, но также и происходит нарушение прав людей на их персональные данные, ведь с внедрением технологий исчезает право на частную жизнь и конфиденциальность. В данной статье автором рассматриваются вопросы развития информационных систем и права. Выявляются правовые пробелы регулирования данной сфере. Рассматривается правовое регулирование вопроса в Российской Федерации, в частности проекта «Безопасный город», который предполагает применение комплекса программно-аппаратных средств и организационных мер для обеспечения видеоохраны и технической безопасности. Делается вывод об отсутствии специального регулирования использования технологий распознавания лиц. Анализируются кейсы нарушения требований законодательства о защите персональных данных в Российской Федерации, Великобритании, США. Рассматривается опыт Китая по применению технологии распознавания лиц во время распространения COVID-19. В заключении отмечается, что для предотвращения преступности данная система крайне актуальна, однако и следом за этим есть необходимость разработки правового регулирования деятельности органов власти по сбору информации и гарантированность незыблемости прав граждан на свободу частной жизни и конфиденциальности персональных данных.

https://dspace.spbu.ru/bitstream/11701/45760/1/10_%D0%A6%D0%B7%D1%8F%2B%D0%B8%2B%D0%B4%D1%80.pdf Цзя Ш., Чжан Ц. Правовая защита права гражданина на изображение лица при применении технологии распознавания лиц в законодательстве Китая/ Ш. Цзя, Ц. Чжан // Правоведение. – 2024. – Т. 68, № 2. – С. 271–283.
В эпоху быстрого развития больших данных биометрическая технология распознавания лиц, идентифицирующая и подтверждающая личность человека по его лицу, постепенно становится объектом внимания общественности. В КНР данная технология стала незаменимым средством сбора информации для государственных и коммерческих организаций. Технология распознавания лиц может быть использована для быстрой идентификации личности и повышения эффективности и точности работы различных служб. Однако у медали две стороны. Широкое использование технологии распознавания лиц оказало влияние на традиционную систему защиты прав гражданина на изображение лица, поэтому соответствующие законы должны быть усовершенствованы в целях предотвращения утечек изображения лица и злоупотреблений использованием изображения лица. Только синхронное продвижение развития технологии распознавания лиц и совершенствование законодательства может обеспечить дальнейшую защиту права гражданина на изображение лица. В данной статье анализируется применение технологии распознавания лиц и связанные с этим риски, объясняется имеющаяся законодательная основа и ее недостатки в Китае, а также выдвигаются соответствующие предложения по дальнейшей защите собранной информации об изображении граждан в рамках технологии распознавания лиц. Использование технологии распознавания лиц оказало влияние на традиционную систему защиты права гражданина на изображение и соответствующие законы должны быть усовершенствованы в этой связи. В данной статье проведен анализ применения технологии распознавания лиц и связанные с ней юридические риски, объясняется законодательная основа и недостатки в этой области в Китае, а также выдвигаются соответствующие предложения по дальнейшей защите информации об изображении гражданина в рамках технологии распознавания лиц. Только под двойной гарантией как продвижение развития технологии распознавания лиц и совершенствование законодательства можно обеспечить дальнейшую защиту права гражданина на изображение. 

https://www.google.com/url?client=internal-element-cse&cx=001431978847466539083:xsldadcvvvo&q=https://judpract.elpub.ru/jour/article/download/142/122&sa=U&ved=2ahUKEwiO9qaCxMyJAxXOBdsEHYZ6EqIQFnoECAgQAg&usg=AOvVaw02j3FS6lKC4iPICKqZGYmO&fexp=72801190,72801191,72801192 Афанасьева Е. Н., Искусственный интеллект и «большие данные» в здравоохранении: области применения и гражданско-правовое регулирование / Е.Н. Афанасьева // Юридическая наука и практика. – 2020. – Т. 16, № 3. – С. 40–49.
Цифровизация практически всех областей жизнедеятельности человека, не обошла стороной и такой стратегический важный сектор как здравоохранение. Медицина, основанная на передовых технологиях сбора «больших данных», машинного обучения и искусственного интеллекта (ИИ), обладает огромным потенциалом для принципиального улучшения качества оказания врачебной помощи на глобальном уровне. Многие алгоритмы цифрового здравоохранения уже достаточно давно и сравнительно успешно работают в потребительских приложениях для смартфонов. Тем не менее, юридические сложности и риски, связанные с разработкой и внедрением алгоритмов искусственного интеллекта и использованием больших данных, весьма существенны, а современное законодательство неспособно учесть их все. Основные вопросы в этой области это: деликтная (и не только) ответственность при использовании систем ИИ и защита персональных данных при обработке больших данных, интеллектуальная собственность, конфиденциальность информации, коммерческая тайна и пр. В данной статье обозначаются основные области применения искусственных интеллектуальных систем и больших данных в области здравоохранения, а также отметить наиболее острые аспекты их правового регулирования. Цифровая медицина обладает огромным потенциалом для изменения существующей системы здравоохранения на глобальном уровне. Многие алгоритмы цифрового здравоохранения уже работают в потребительских приложениях для смартфонов, а другие, вероятно, войдут в медицинскую практику в ближайшие годы. Тем не менее, юридические риски, весьма существенны. Несмотря на колоссальную помощь «умных приложений», нельзя оставлять без внимания тот факт, что врачи не могут полностью понять все технологии, которые они используют, или выбор, который такие технологии помогают им сделать, когда им не предоставляется соответствующая информация. В конечном итоге, все неурегулированные и непонятные как для медиков, так и для юристов аспекты, будут иметь реальные последствия для всех членов общества. На данном этапе очевидно, что: существующее законодательство не готово объять обширный круг вновь появившихся вопросов; необходимо восполнять пробелы новым правотворчеством; важно как можно скорее обеспечить серьезную коллаборацию юристов, медиков и программистов на государственном и международном уровнях.

https://www.google.com/url?client=internal-element-cse&cx=001431978847466539083:xsldadcvvvo&q=https://law-journal.hse.ru/article/download/20125/17629&sa=U&ved=2ahUKEwjs0IiZxcyJAxXOcfEDHaEKDpo4ChAWegQIAxAB&usg=AOvVaw2cD_9Som3LcX2-8oIdv3M8&fexp=72801190,72801191,72801192 Талапина Э.В., Обработка данных при помощи искусственного интеллекта и риски дискриминации / Э.В. Талапина // Право. Журнал Высшей школы экономики. – 2022. – Т. 15. № 1. – С. 4-27. 
Дискриминация создает угрозу равенству как основному концепту правового государства. Эта проблема обретает новое звучание в связи с использованием искусственного интеллекта для принятия значимых юридических решений, поскольку искусственный интеллект способен принимать ошибочные решения в отношении конкретных лиц, в основе которых часто лежит дискриминация. Целью статьи стало изучение рисков дискриминации, чтобы учесть и избегать их в будущем правовом регулировании. Исследование основано на анализе доктринальных и нормативных источников разных стран, изучении имеющегося опыта использования искусственного интеллекта. Конкретным методом интеллектуального анализа данных является профилирование, которое не оставляет большого пространства для автономии и самоопределения личности. В связи с этим предлагается переоценить теорию информационного самоопределения, используя ее потенциал разделения ответственности между обладателем данных и обработчиком. Ввиду явных дискриминационных рисков профилирования некоторые операции уже запрещены (например, редлайнинг в США, генетическое профилирование в области страхования и занятости в ряде стран). Отдельно должны изучаться предиктивные способности искусственного интеллекта в отношении юридической оценки поведения конкретного человека. Опыт алгоритмического прогнозирования поведения человека, накопленный в рамках уголовного правосудия в США, свидетельствует о вероятностном характере такой оценки. Это способно нарушить права человека на справедливое судебное разбирательство и индивидуализацию наказания, если алгоритмическая оценка станет единственным основанием для вынесения судебного решения. В целом развитие приложений по решению рутинных правовых проблем, которые будут давать результаты на основании прошлых судебных решений, особо актуально в странах общего права, где господствует прецедентное право. С учетом того, что Россия принадлежит к континентальной системе права перспективы использования американского опыта сомнительны. Рассмотрение конкретных видов недостатков, которые способны привести к дискриминационной обработке данных, позволило сделать выводы о контурах будущего законодательства в отношении деятельности искусственного интеллекта с учетом всех проанализированных рисков дискриминации. 

https://app.dimensions.ai/details/publication/pub.1175585491?search_mode=content&search_text=%D0%B8%D1%81%D0%BA%D1%83%D1%81%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D1%8B%D0%B9%20%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%20%D0%B8%20%D0%BF%D0%B5%D1%80%D1%81%D0%BE%D0%BD%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5&search_type=kws&search_field=full_search Филипова И.А. нейросети: применение, вопросы этики и права / И.А. Филипова // Bulletin of the South Ural State University series Law. – 2023. – №23(4). – С. 76-81.
Использование искусственных нейронных сетей на практике в последние годы стало быстро расти, они все чаще применяются в бизнесе, в медицине и даже в государственном управлении. Такое распространение нейросетей как инструмента принятия решений меняет содержание ряда общественных отношений, тем самым ставя перед юристами новые задачи, касающиеся создания адекватного происходящим изменениям правового регулирования. На основе анализа теоретических положений и практических особенностей, относящихся к обучению искусственных нейронных сетей в целях дальнейшего их использования в качестве инструмента по поиску оптимальных решений, в статье сделаны выводы о ключевых вопросах этико-правового характера, без разрешения которых негативные эффекты от использования нейросетей проявятся значительно сильнее. Один из таких вопросов – необходимость «честности» обучения искусственной нейронной сети, чтобы она не воспроизводила общественные предрассудки и предпочтения разработчиков, дискриминируя отдельные социальные группы. Еще один вопрос касается прозрачности принятия решений нейросетью, отсутствие понимания логики в выборе решения не способствует установлению доверия со стороны людей. Не менее важен и вопрос о сохранении конфиденциальности данных: как защитить персональные данные, если они нужны нейросети для принятия решения? Результаты исследования позволяют четче сформулировать вопросы, требующие первоочередного внимания правоведов, чтобы вести поиск решений по ним юридическим сообществом. Ведь использование нейронных сетей практикующими юристами в своей профессиональной деятельности в рамках направления LegalTech параллельно с изучением теоретических моментов позволяет при-близиться к оптимальному решению поставленных вопросов.

https://app.dimensions.ai/details/publication/pub.1181266298?search_mode=content&search_text=%D0%B8%D1%81%D0%BA%D1%83%D1%81%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D1%8B%D0%B9%20%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%20%D0%B8%20%D0%BF%D0%B5%D1%80%D1%81%D0%BE%D0%BD%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5&search_type=kws&search_field=full_search Галкина Н.М., Кузнецова Д.В., регулирование и защита персональных медицинских данных в эпоху ИИ: международный опыт / Н.М. Галкина, Д.В. Кузнецова // Theoretical and Applied Law. - October 2024. - №0(3). – С. 96-106.
Искусственный интеллект активно захватывает одну сферу за другой, и особые успехи и достижения можно наблюдать в сфере медицины и медицинских технологий. Однако внедрение ИИ порождает ряд практических и этических вопросов. Одним из главных является вопрос работы с персональными данными, поскольку доступ к большому количеству данных о здоровье пациентов играет ключевую роль в развитии и использовании ИИ в медицине. Наиболее удобным решением для их использования является их предварительная анонимизация. Однако при анонимизации существует риск повторной идентификации и потери информативности данных. В рамках данной статьи рассматривается опыт в сфере правового регулирования обработки персональных медицинских данных при использовании систем искусственного интеллекта в медицине на примере США, ЕС и Сингапура. Каждая страна стремится найти баланс между защитой конфиденциальности персональных данных и развитием технологических инноваций. Анализ показывает, что акцент на развитие искусственного интеллекта требует особых условий в области защиты персональных данных. И наоборот, жесткие стандарты защиты персональных данных могут оказать ограничительное влияние.

